{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_mnist.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQ6u/kb1gCR5C3AFJYbEXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RogerHeederer/ML_practice_MyFirstML_B/blob/master/MLP_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPXtdZU2llR5",
        "colab_type": "text"
      },
      "source": [
        "source reference : https://github.com/wikibook/machine-learnin\n",
        "\n",
        "위 레퍼런스를 참조하여 공부하였으며, 필요하다고 생각되는 부분에 추가적인 설명 및 그림들을 덧붙였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOKQDlNwZ0_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(678)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj_Texn_Z-xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from IPython.display import Image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAi0r1tvmefp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "066d0761-7cd0-4465-9994-ea640d7a507c"
      },
      "source": [
        "# MLP 다층퍼셉트론 구조\n",
        "Image(url = \"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/dropout.png\", width=500, height=250)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/dropout.png\" width=\"500\" height=\"250\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJDTHWtVmyOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5f75c809-3704-4601-a9fd-8b8dc8e967c0"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPhixT4zm9sP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "65d34358-c9f7-43b2-ecb0-6dbf6ea4a0de"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwv0E6oUnNIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e9f9341-a41c-4870-93a7-cd452b38f9c6"
      },
      "source": [
        "x_train[59999]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.14901961, 0.1882353 , 0.1882353 , 0.08627451,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.24313726, 0.38039216,\n",
              "        0.7764706 , 0.9529412 , 0.99607843, 0.99607843, 0.83137256,\n",
              "        0.10588235, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.2627451 , 0.6745098 , 0.99607843,\n",
              "        0.99607843, 0.88235295, 0.85490197, 0.85490197, 0.92941177,\n",
              "        0.972549  , 0.15686275, 0.        , 0.08235294, 0.6431373 ,\n",
              "        0.73333335, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34901962, 0.85882354, 0.99607843, 0.38039216,\n",
              "        0.2627451 , 0.05490196, 0.        , 0.        , 0.36078432,\n",
              "        0.90588236, 0.47843137, 0.09019608, 0.79607844, 0.9254902 ,\n",
              "        0.23137255, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.09803922, 0.8509804 , 0.9490196 , 0.36078432, 0.01568628,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
              "        0.5764706 , 0.99215686, 0.9411765 , 0.9098039 , 0.36078432,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.39607844, 1.        , 0.36078432, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.4117647 ,\n",
              "        0.99607843, 0.99607843, 0.69411767, 0.04313726, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.654902  , 0.95686275, 0.16078432, 0.        , 0.        ,\n",
              "        0.        , 0.02745098, 0.29803923, 0.78039217, 0.93333334,\n",
              "        0.9372549 , 0.36862746, 0.03921569, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.7529412 , 0.4745098 , 0.        , 0.        , 0.00784314,\n",
              "        0.24705882, 0.7058824 , 0.99607843, 0.9137255 , 0.49411765,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.74509805, 0.76862746, 0.05490196, 0.00784314, 0.38039216,\n",
              "        0.99607843, 0.9882353 , 0.57254905, 0.20392157, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.50980395, 0.88235295, 0.2784314 , 0.7058824 , 0.9098039 ,\n",
              "        0.70980394, 0.23529412, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.50980395, 0.99607843, 0.99607843, 0.9019608 , 0.18039216,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02352941, 0.3019608 ,\n",
              "        0.95686275, 0.99607843, 0.63529414, 0.01568628, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.43137255, 0.99607843,\n",
              "        0.85490197, 0.99607843, 0.45490196, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.5137255 , 0.99607843, 0.6039216 ,\n",
              "        0.10980392, 0.8352941 , 0.3372549 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.25882354, 0.81960785, 0.6       , 0.07450981,\n",
              "        0.07450981, 0.9137255 , 0.23529412, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.5568628 , 0.99607843, 0.64705884, 0.        ,\n",
              "        0.05490196, 0.84705883, 0.654902  , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.3529412 , 0.99607843, 0.6862745 , 0.        ,\n",
              "        0.07058824, 0.8980392 , 0.36078432, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.10196079, 0.8980392 , 0.9764706 , 0.6901961 ,\n",
              "        0.87058824, 0.95686275, 0.17254902, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.28627452, 0.75686276, 0.77254903,\n",
              "        0.5254902 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHNvWpL1nVH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf905cf8-ac3d-4ff2-ced7-48818df38704"
      },
      "source": [
        "y_train[0:15]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgdulKKEnXSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "727c426f-e93d-4499-c077-1237156d4b29"
      },
      "source": [
        "print(\"train data has \" + str(x_train.shape[0]) + \"samples\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data has 60000samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfFBvJ-1oNwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd1e7fe7-3599-4b37-ccc2-30b07ae5da3d"
      },
      "source": [
        "print(\"every train data is \"+ str(x_train.shape[1]) + \" * \" + str(x_train.shape[2]) + \"image\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "every train data is 28 * 28image\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh8rrUAFomQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "56ea0018-a3d2-4c6e-81f8-627ad62e9451"
      },
      "source": [
        "print(\"test data has \" + str(x_test.shape[0]) + \" samples\")\n",
        "print(\"every test data is \" + str(x_test.shape[1]) \n",
        "      + \" * \" + str(x_test.shape[2]) + \" image\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test data has 10000 samples\n",
            "every test data is 28 * 28 image\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rmgCB3FotVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#데이터 정규화 - 학습시간 단축 및 퍼포먼스 향상\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "gray_scale = 255\n",
        "x_train /= gray_scale\n",
        "x_test /= gray_scale"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjXMeLhXraGM",
        "colab_type": "text"
      },
      "source": [
        "##**텐서플로우로 MLP 구현하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mbylUIvpNKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "93c03d28-3e6d-47be-a2f8-58f9455443cb"
      },
      "source": [
        "Image(url= \"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/dropout.png\", width=500, height=250)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/dropout.png\" width=\"500\" height=\"250\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oONLdOMnrlo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c8c8eece-2727-4a9f-f7ce-055c8dcc7cb3"
      },
      "source": [
        "# 다층퍼셉트론의 입력 레이어에 데이터를 넣기 위해서는 (28,28) 2d tensor를 1d 타입으로 바꿔줘야 한다\n",
        "# 즉, 행렬 데이터 타입을 배열 데이터 타입으로 전환해줘야 함\n",
        "Image(url= \"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/reshape_mnist.png\", width=300, height=150)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/reshape_mnist.png\" width=\"300\" height=\"150\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGN8a2-Rr5XO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "                    Flatten(input_shape=(28,28)),\n",
        "                    Dense(256, activation='relu'), #첫번째 히든레이어\n",
        "                    Dense(128, activation='relu'), #두번째 히든레이어\n",
        "                    Dropout(0.1),#두번째 히든레이어에 드랍아웃 적용\n",
        "                    Dense(10),# 세번째 히든 레이어\n",
        "                    Activation('softmax')\n",
        "])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsMPEJ-7svlB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "f48836ef-4cc9-4a5c-8bd1-6b335ccf2d46"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyxdd40_ty98",
        "colab_type": "text"
      },
      "source": [
        "- 인풋값 784 * 인풋을 받아주는 첫번째 레이어의 노드 수 256 + 노드마다의 편향값 256 = 200960\n",
        "- 첫번째 레이어로부터 나온 노드 256 * 두번째 레이어의 노드 수 128 + 두번째 레이어의 노드마다 편향값 128 = 32896\n",
        "- 두번째 레이어로부터 나온 노드 128 * 세번째 레이어의 노드 수 10 + 세번째 레이어의 노드마다 편향값 10 = 1290\n",
        "- flatten과 softmax는 노드가 없으므로 파라미터 값은 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtABK97PsyFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#softmax를 통해 나온 예측값 y와 실측값 y_hat을 비교하여, 둘 간의 loss가 최소인 상태로 만들고자 한다\n",
        "#그러기 위해 sparse_categorical_crossentopy를 사용하는데, 레이블 값을 원 핫 인코딩으로 자동 변경하여 크로스 엔트로피를 측정한다.\n",
        "#그걸 adam 옵티마이져가 back propagation을 진행하면서 수행해준다.\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffUScu9KxYsV",
        "colab_type": "text"
      },
      "source": [
        "###조기종료 (Early Stopping)\n",
        "매 주기(epoch)마다 검증 데이터로 검증 정확도를 측정한다.\n",
        "val_accuracy가 5번 연속으로 개선되지 않을 시, 조기에 훈련 종료를 한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G48dqvUEtwuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [ EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=False),\n",
        "              ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True)]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jRq3XxSxpSg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "504afcbd-5daf-4dbb-8171-cacaa05c0a96"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=300, batch_size=1000,\n",
        "          validation_split = 0.1, callbacks=callbacks) # validation_split=0.1 은 6만개 데이터 중 54000개는 train, 6000개는 validation으로 분할"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "54/54 [==============================] - 2s 28ms/step - loss: 0.6740 - accuracy: 0.8117 - val_loss: 0.2151 - val_accuracy: 0.9403\n",
            "Epoch 2/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.2391 - accuracy: 0.9307 - val_loss: 0.1459 - val_accuracy: 0.9638\n",
            "Epoch 3/300\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.1713 - accuracy: 0.9505 - val_loss: 0.1238 - val_accuracy: 0.9665\n",
            "Epoch 4/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.1341 - accuracy: 0.9607 - val_loss: 0.1038 - val_accuracy: 0.9688\n",
            "Epoch 5/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.1091 - accuracy: 0.9682 - val_loss: 0.0910 - val_accuracy: 0.9730\n",
            "Epoch 6/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0922 - accuracy: 0.9729 - val_loss: 0.0867 - val_accuracy: 0.9742\n",
            "Epoch 7/300\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0770 - accuracy: 0.9781 - val_loss: 0.0807 - val_accuracy: 0.9758\n",
            "Epoch 8/300\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0665 - accuracy: 0.9809 - val_loss: 0.0766 - val_accuracy: 0.9785\n",
            "Epoch 9/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0566 - accuracy: 0.9841 - val_loss: 0.0763 - val_accuracy: 0.9768\n",
            "Epoch 10/300\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0485 - accuracy: 0.9860 - val_loss: 0.0721 - val_accuracy: 0.9795\n",
            "Epoch 11/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 0.0729 - val_accuracy: 0.9792\n",
            "Epoch 12/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0361 - accuracy: 0.9897 - val_loss: 0.0730 - val_accuracy: 0.9785\n",
            "Epoch 13/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0313 - accuracy: 0.9914 - val_loss: 0.0698 - val_accuracy: 0.9813\n",
            "Epoch 14/300\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0279 - accuracy: 0.9928 - val_loss: 0.0670 - val_accuracy: 0.9815\n",
            "Epoch 15/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0246 - accuracy: 0.9935 - val_loss: 0.0714 - val_accuracy: 0.9805\n",
            "Epoch 16/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.0661 - val_accuracy: 0.9817\n",
            "Epoch 17/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 0.0678 - val_accuracy: 0.9805\n",
            "Epoch 18/300\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.0163 - accuracy: 0.9961 - val_loss: 0.0716 - val_accuracy: 0.9803\n",
            "Epoch 19/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 0.0683 - val_accuracy: 0.9807\n",
            "Epoch 20/300\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.0701 - val_accuracy: 0.9815\n",
            "Epoch 21/300\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.0693 - val_accuracy: 0.9818\n",
            "Epoch 22/300\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.0658 - val_accuracy: 0.9832\n",
            "Epoch 23/300\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.0645 - val_accuracy: 0.9837\n",
            "Epoch 24/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0709 - val_accuracy: 0.9828\n",
            "Epoch 25/300\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0704 - val_accuracy: 0.9818\n",
            "Epoch 26/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0716 - val_accuracy: 0.9833\n",
            "Epoch 27/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0731 - val_accuracy: 0.9830\n",
            "Epoch 28/300\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0715 - val_accuracy: 0.9830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3a65059f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af6CXjC8x8EE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b2c0649a-403c-403c-836f-cf992401730c"
      },
      "source": [
        "result = model.evaluate(x_test, y_test, verbose = 1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.9803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igf-cNFtyNUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5cfd48c8-cbc7-41ac-bc6a-7b00ed6965ec"
      },
      "source": [
        "print('test loss, test acc:', result)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss, test acc: [0.07475697994232178, 0.9803000092506409]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvQt_0D7zMrE",
        "colab_type": "text"
      },
      "source": [
        "##학습이 어떤식으로 이루어져서 정답을 맞추는지가 직관적으로 이해되지 않아 서술해봄"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQkILP7SyVm-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c0a0cf3-80a4-4f9f-ebf3-7585d4cfeb7b"
      },
      "source": [
        "#x_trian 샘플은 60000개가 있음. 각 샘플마다의 정답이 레이블 되어 있음\n",
        "#예를 들어 x_train[59999] :6만번째 샘플(그림)의 정답은 8이다\n",
        "x_train[59999]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.14901961, 0.1882353 , 0.1882353 , 0.08627451,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.24313726, 0.38039216,\n",
              "        0.7764706 , 0.9529412 , 0.99607843, 0.99607843, 0.83137256,\n",
              "        0.10588235, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.2627451 , 0.6745098 , 0.99607843,\n",
              "        0.99607843, 0.88235295, 0.85490197, 0.85490197, 0.92941177,\n",
              "        0.972549  , 0.15686275, 0.        , 0.08235294, 0.6431373 ,\n",
              "        0.73333335, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34901962, 0.85882354, 0.99607843, 0.38039216,\n",
              "        0.2627451 , 0.05490196, 0.        , 0.        , 0.36078432,\n",
              "        0.90588236, 0.47843137, 0.09019608, 0.79607844, 0.9254902 ,\n",
              "        0.23137255, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.09803922, 0.8509804 , 0.9490196 , 0.36078432, 0.01568628,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
              "        0.5764706 , 0.99215686, 0.9411765 , 0.9098039 , 0.36078432,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.39607844, 1.        , 0.36078432, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.4117647 ,\n",
              "        0.99607843, 0.99607843, 0.69411767, 0.04313726, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.654902  , 0.95686275, 0.16078432, 0.        , 0.        ,\n",
              "        0.        , 0.02745098, 0.29803923, 0.78039217, 0.93333334,\n",
              "        0.9372549 , 0.36862746, 0.03921569, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.7529412 , 0.4745098 , 0.        , 0.        , 0.00784314,\n",
              "        0.24705882, 0.7058824 , 0.99607843, 0.9137255 , 0.49411765,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.74509805, 0.76862746, 0.05490196, 0.00784314, 0.38039216,\n",
              "        0.99607843, 0.9882353 , 0.57254905, 0.20392157, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.50980395, 0.88235295, 0.2784314 , 0.7058824 , 0.9098039 ,\n",
              "        0.70980394, 0.23529412, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.50980395, 0.99607843, 0.99607843, 0.9019608 , 0.18039216,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02352941, 0.3019608 ,\n",
              "        0.95686275, 0.99607843, 0.63529414, 0.01568628, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.43137255, 0.99607843,\n",
              "        0.85490197, 0.99607843, 0.45490196, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.5137255 , 0.99607843, 0.6039216 ,\n",
              "        0.10980392, 0.8352941 , 0.3372549 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.25882354, 0.81960785, 0.6       , 0.07450981,\n",
              "        0.07450981, 0.9137255 , 0.23529412, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.5568628 , 0.99607843, 0.64705884, 0.        ,\n",
              "        0.05490196, 0.84705883, 0.654902  , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.3529412 , 0.99607843, 0.6862745 , 0.        ,\n",
              "        0.07058824, 0.8980392 , 0.36078432, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.10196079, 0.8980392 , 0.9764706 , 0.6901961 ,\n",
              "        0.87058824, 0.95686275, 0.17254902, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.28627452, 0.75686276, 0.77254903,\n",
              "        0.5254902 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dyx-b1wy4pc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "911378c1-d189-46a4-a129-94853b3ac5b8"
      },
      "source": [
        "y_train[59999]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgKGd7xUz1lJ",
        "colab_type": "text"
      },
      "source": [
        "**앞서 구성한 다층퍼셉트론 네트워크에서 x_train[59999]가 가지고 있는 28*28 = 784개의 인풋값을 전부 계산해서 내린 결론의 값은 숫자 8 이미지이구나! 라고 학습을 한다. 이런 작업을 x_train[0]~[59999]까지 전부 머신이 수행한다. 그렇게 학습된 머신은 새로운 테스트 데이터셋에 적용시켜서 숫자 그림을 잘 맞추는지 아닌지 테스트 하는 것이 MLP_mnist의 목표**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKAaplgizyR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}